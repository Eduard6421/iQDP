{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5424379-08e3-44a3-a2ee-859f01d3b932",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import skimage.io as sk\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchvision.models import vgg16,VGG16_Weights\n",
    "from torch.utils.data import Dataset,DataLoader,random_split\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from joblib import dump, load\n",
    "\n",
    "\n",
    "import torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f098a19-7511-4af6-94dc-1fcc60a74df6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94509d6d-3f40-4c6a-846c-6a72dff12ec9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CSV_FILEPATH = '/../../Referenced-Models/VSD_dataset.csv'\n",
    "IMAGE_FOLDER = '/../../cnnimageretrieval-pytorch/data/test/pascalvoc/jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ff36501-4788-4bf7-a7bd-1c373236c796",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class VGGExtractor():\n",
    "    \n",
    "    def __init__(self, ):\n",
    "    \n",
    "        # Pytorch exposes easy preprocess steps so that we can match the input data\n",
    "        self.vgg16_model = vgg16(weights=VGG16_Weights.DEFAULT)\n",
    "\n",
    "        # Remove last linear and keep only 4096d vectors\n",
    "        self.vgg16_model.classifier = self.vgg16_model.classifier[:-1]\n",
    "        self.vgg16_model.to(device)\n",
    "    \n",
    "        for parameter in self.vgg16_model.parameters():\n",
    "            parameter.requires_grad = False\n",
    "        \n",
    "        self.vgg16_model.eval()\n",
    "        \n",
    "    def __call__(self, image):\n",
    "        \n",
    "        return self.vgg16_model(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adfddf78-c28f-42d5-81ec-374d848fa453",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Custom dataset class\n",
    "\n",
    "class ImageDifficultyDataset(Dataset):\n",
    "    def __init__(self, label_dir, image_dir, transform=None):\n",
    "        df = pd.read_csv(label_dir, sep=',', header=None)\n",
    "        df = df.rename(columns = {0:'img_name',1:'difficulty_score'})\n",
    "        \n",
    "        self.data = df\n",
    "        self.rootDir = image_dir\n",
    "        self.transform = transforms.Compose([transforms.ToTensor(), transform])\n",
    "        \n",
    "        return\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        imagePath = self.rootDir + \"/\" + self.data['img_name'][idx] + '.jpg'\n",
    "        image = Image.open(imagePath)\n",
    "        if(self.transform):\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        score = self.data['difficulty_score'][idx]\n",
    "            \n",
    "        return image, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d48bf59d-a72a-417a-8ab7-e86a542eed80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_input_output_tensors(dataloader):\n",
    "    input_tensor_array = []\n",
    "    output_tensor_array = []\n",
    "\n",
    "    print('Extracting features....')\n",
    "    with torch.no_grad():\n",
    "        for idx,item in enumerate(dataloader):\n",
    "            print('Batch {} / {}'.format(idx+1,len(dataloader)))\n",
    "            (image_batches, score_batches) = item\n",
    "            image_batches = image_batches.to(device)\n",
    "            results = model(image_batches)\n",
    "            \n",
    "            input_tensor_array.append(results)\n",
    "            output_tensor_array.append(score_batches)\n",
    "            \n",
    "    input_tensor_array = torch.stack(input_tensor_array[:-1],dim = 0)\n",
    "    input_tensor_array = input_tensor_array.reshape(-1,4096)\n",
    "    input_tensor_array = np.array(input_tensor_array.cpu())\n",
    "    \n",
    "    output_tensor_array = torch.stack(output_tensor_array[:-1],dim = 0)\n",
    "    output_tensor_array = output_tensor_array.reshape(-1)\n",
    "    output_tensor_array = np.array(output_tensor_array.cpu())\n",
    "    \n",
    "    return input_tensor_array,output_tensor_array\n",
    "            \n",
    "\n",
    "def generate_models():\n",
    "    #Dataset Reads\n",
    "    dataset = ImageDifficultyDataset(label_dir=CSV_FILEPATH,image_dir=IMAGE_FOLDER, transform =VGG16_Weights.DEFAULT.transforms() )\n",
    "\n",
    "    train_size = int(0.80*int(len(dataset)))\n",
    "    validation_size = int(0.10*int(len(dataset)))\n",
    "    test_size  = len(dataset) - (train_size + validation_size)\n",
    "\n",
    "    train_dataset, validation_dataset, test_dataset = random_split(dataset, lengths=[train_size,validation_size,test_size],generator=torch.Generator().manual_seed(420))\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=300,shuffle=True)\n",
    "    validation_dataloader = torch.utils.data.DataLoader(validation_dataset, batch_size=100, shuffle=True)\n",
    "    test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=True)\n",
    "    \n",
    "    \n",
    "    train_input_tensor,train_output_tensor = get_input_output_tensors(train_dataloader)\n",
    "    validation_input_tensor,validation_output_tensor = get_input_output_tensors(validation_dataloader)\n",
    "    test_input_tensor,test_output_tensor = get_input_output_tensors(test_dataloader)    \n",
    "    \n",
    "    \n",
    "    scaler = preprocessing.StandardScaler().fit(train_input_tensor)\n",
    "    normalized_train_features = scaler.transform(train_input_tensor)\n",
    "    normalized_validation_features = scaler.transform(validation_input_tensor)\n",
    "    normalized_test_features = scaler.transform(test_input_tensor)\n",
    "    \n",
    "    print('Starting training...')\n",
    "    svr = SVR(degree=3, epsilon = 0.1)\n",
    "    svr.fit(normalized_train_features,train_output_tensor)\n",
    "\n",
    "    print('Train score: {}'.format(svr.score(normalized_train_features, train_output_tensor)))\n",
    "    print('Validation score: {}'.format(svr.score(normalized_validation_features,validation_output_tensor )))\n",
    "    print('Test score: {}'.format(svr.score(normalized_test_features, test_output_tensor)))\n",
    "\n",
    "    return scaler, svr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c0c4365-9d4e-44ac-9bab-155fddd7c5a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d534b68db364726a12235c0fc67c66a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/528M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = VGGExtractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b207b19d-24ed-4e44-90cc-11074a3feafd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features....\n",
      "Batch 1 / 31\n",
      "Batch 2 / 31\n",
      "Batch 3 / 31\n",
      "Batch 4 / 31\n",
      "Batch 5 / 31\n",
      "Batch 6 / 31\n",
      "Batch 7 / 31\n",
      "Batch 8 / 31\n",
      "Batch 9 / 31\n",
      "Batch 10 / 31\n",
      "Batch 11 / 31\n",
      "Batch 12 / 31\n",
      "Batch 13 / 31\n",
      "Batch 14 / 31\n",
      "Batch 15 / 31\n",
      "Batch 16 / 31\n",
      "Batch 17 / 31\n",
      "Batch 18 / 31\n",
      "Batch 19 / 31\n",
      "Batch 20 / 31\n",
      "Batch 21 / 31\n",
      "Batch 22 / 31\n",
      "Batch 23 / 31\n",
      "Batch 24 / 31\n",
      "Batch 25 / 31\n",
      "Batch 26 / 31\n",
      "Batch 27 / 31\n",
      "Batch 28 / 31\n",
      "Batch 29 / 31\n",
      "Batch 30 / 31\n",
      "Batch 31 / 31\n",
      "Extracting features....\n",
      "Batch 1 / 12\n",
      "Batch 2 / 12\n",
      "Batch 3 / 12\n",
      "Batch 4 / 12\n",
      "Batch 5 / 12\n",
      "Batch 6 / 12\n",
      "Batch 7 / 12\n",
      "Batch 8 / 12\n",
      "Batch 9 / 12\n",
      "Batch 10 / 12\n",
      "Batch 11 / 12\n",
      "Batch 12 / 12\n",
      "Extracting features....\n",
      "Batch 1 / 12\n",
      "Batch 2 / 12\n",
      "Batch 3 / 12\n",
      "Batch 4 / 12\n",
      "Batch 5 / 12\n",
      "Batch 6 / 12\n",
      "Batch 7 / 12\n",
      "Batch 8 / 12\n",
      "Batch 9 / 12\n",
      "Batch 10 / 12\n",
      "Batch 11 / 12\n",
      "Batch 12 / 12\n",
      "Starting training...\n",
      "Train score: 0.5999889232862394\n",
      "Validation score: 0.13928285529834916\n",
      "Test score: 0.20611406080081862\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model.joblib']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler,svr = generate_models()\n",
    "dump(scaler, 'scaler.joblib')\n",
    "dump(svr, 'svr.joblib')\n",
    "dump(model,'model.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "5efb5c8d63a54c73d8d27071022adad53c6f3df0ecaf8b2d6fe4415ee6c014ca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
